{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63eddb09",
   "metadata": {},
   "source": [
    "## Clustering ðŸ“¦ðŸ“¦ðŸ“¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a59a7f",
   "metadata": {},
   "source": [
    "#### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#scikit is an open source data analysis library, and the gold standard for Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed0805",
   "metadata": {},
   "source": [
    "#### 1. Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('penguins_cluster.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d074caef",
   "metadata": {},
   "source": [
    "#### 2. Show the first 10 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711600e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb83ef28",
   "metadata": {},
   "source": [
    "#### 3. We are going work with the numerical data. Filter out the species column, name the dataset df_num and show the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee64608",
   "metadata": {},
   "source": [
    "#### 4. Use the `describe()` function to see if the variables in the data set have large differences between their ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735fe08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11ba22d3",
   "metadata": {},
   "source": [
    "#### 5. Do you see any large difference? If yes which features? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa75d71",
   "metadata": {},
   "source": [
    "#### 6. If you think one or more features may dominate over the other ones, you need to standardize the data. Name the scaled data as penguins_scaled.\n",
    "\n",
    "**Feature Scaling is an important technique that mostly comes to the picture during pre-processing step in Machine Learning.**\n",
    " \n",
    "We use feature scaling when the variables in the data set have large differences in order of magnitude, or when they are similar in that sense but measured with different metrics such as meters vs kilometers, etc. \n",
    "These differences cause problems for many models. For example, if one of the features has a way higher order of magnitude, this particular feature will dominate over the other ones.\n",
    "\n",
    "In order to avoid this issue, we will perform feature scaling which brings all of the measurements into a similar range of values. There are different approaches to feature scaling:\n",
    "- normalization - it maps the data in the range between 0 and 1 (the minimal data point will be mapped to 0 and the maximal one to 1). Note that if the data consist of any outliers it will influence the new distribution heavily.\n",
    "- standarization - it maps the data in a way that all the new values will oscilate around 0 with a unit standard deviation. In this case, the mapped values are not restricted to a particular range. Standarization is widely used when the data has a gaussian distribution.\n",
    "\n",
    "Imagine you have a 2 dimensional dataset representing the body measurements of a group of adult people: height in meters and weight in kg. The height ranges respectively from 1 to 2 and weight from 40 to 200. It does not matter which model you use on this dataset, the weight feature will dominate over the height and it will contribute more to the computation.  \n",
    "\n",
    "In python we can use scikit-learn to scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ebdd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df_num)\n",
    "df_num_scaled = scaler.transform(df_num)\n",
    "df_num_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948c2f0",
   "metadata": {},
   "source": [
    "#### 7. The standardized data is an array. Please convert the array to a pandas dataframe, Name the data df_penguins. (Hint: columns = df_num.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f76534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penguins = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0a04d",
   "metadata": {},
   "source": [
    "#### 8. Check how does the scaled data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9caa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4508143",
   "metadata": {},
   "source": [
    "#### 9. Let's imagine that we don't know anything about the data and we assume there might be only two groups of penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf66a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(df_penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d0129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "340e8fec",
   "metadata": {},
   "source": [
    "#### 10. Let's check which labels we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaaa560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a cluster to each example\n",
    "clusters = kmeans.predict(df_penguins)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# retrieve unique clusters\n",
    "labels = np.unique(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clusters).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494fe2c",
   "metadata": {},
   "source": [
    "#### 11. Now we are adding the defined clusters to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c292a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d993d82",
   "metadata": {},
   "source": [
    "#### 12. Add real penguins species to the dataframe again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edb303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a9f42c9",
   "metadata": {},
   "source": [
    "#### 13. Let's check the mapping between the species and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8b0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4b7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c29f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ff4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce580ac",
   "metadata": {},
   "source": [
    "#### 14. Let's use elbow method to see how many clusters are recommended for this dataset (we know that there are 3 species in the dataset)\n",
    "\n",
    "**The Elbow Method**\n",
    "\n",
    "The elbow method is one of the most well-known methods in machine learning and could be also used for finding the optimal number of clusters. With calculating the **Within-Cluster-Sum of Squared Errors ([WSS](https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb))** for different values of k we can choose the k for which WSS first starts to decrease. In a plot this will show an elbow joint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa879c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = range(2, 10) #let's give it a range\n",
    "inertia = []\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k,\n",
    "                    random_state=1234)\n",
    "    kmeans.fit(df_penguins)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, inertia, 'bx-') # shows the x symbols on the graph\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(np.arange(min(K), max(K), 1.0))\n",
    "plt.title('Elbow Method showing the optimal k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e68b30",
   "metadata": {},
   "source": [
    "We can see a light elbow for k = 3 which fits our knowledge of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd5549",
   "metadata": {},
   "source": [
    "#### 15. Repeat k-means clustering with k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(df_penguins)\n",
    "\n",
    "clusters = kmeans.predict(df_penguins)\n",
    "df_clustered_3 = df_penguins.copy() \n",
    "df_clustered_3[\"cluster\"] = clusters\n",
    "df_clustered_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88316764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered_3['species'] = df[['species']]\n",
    "df_clustered_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie_3 = df_clustered_3.loc[df_clustered_3['species'] == 'Adelie']\n",
    "adelie['cluster'].unique() # which label got Adelie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8254f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130bb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
